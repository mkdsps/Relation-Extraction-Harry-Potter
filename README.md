
# ğŸ§™â€â™‚ï¸ Projekat: Ekstrakcija Relacija u Domenu Harry Pottera

## ğŸ¯ Cilj projekta

Cilj ovog projekta je razvoj modela za ekstrakciju relacija izmeÄ‘u entiteta u tekstu, u okviru fiktivnog domena Harry Potter univerzuma.

Za dati paragraf, model identifikuje entitete (likove, kuÄ‡e, predmete, Äini, lokacije) i relacije meÄ‘u njima. Rezultat se moÅ¾e opcionalno vizualizovati kao graf.

Primer:

Input:
"Magix is using broom to fly, to his house Gryffindor."

Output:
```json
{
  "tokens": ["Magix", "is", "using", "broom", "to", "fly,", "to", "his", "house", "Gryffindor."],
  "entities": [
    { "id": 1, "text": "Magix", "type": "CHARACTER", "token_start": 0, "token_end": 0 },
    { "id": 2, "text": "broom", "type": "MAGIC_ITEM", "token_start": 3, "token_end": 3 },
    { "id": 3, "text": "Gryffindor", "type": "HOUSE", "token_start": 9, "token_end": 9 }
  ],
  "relations": [
    { "type": "uses", "head": 1, "tail": 2 },
    { "type": "member-of-house", "head": 1, "tail": 3 }
  ]
}
```
(+ opcioni prikaz kao graf pomoÄ‡u `networkx`)


## âš¡ ZaÅ¡to Harry Potter?

Harry Potter univerzum je idealan za ovakav tip zadatka jer:
- Tekstovi su lako dostupni i poznati
- Semantika relacija je jasna
- OmoguÄ‡ava fokus na NLP tehniku umesto borbe sa "messy" podacima


## ğŸ§© Entiteti i relacije

Entiteti:
- CHARACTER â€“ likovi (Harry, Hermione, Dumbledore...)
- HOUSE â€“ Hogwarts kuÄ‡e (Gryffindor, Slytherin...)
- MAGIC_ITEM â€“ magiÄni predmeti (wand, broomstick...)
- SPELL â€“ Äarolije (Expelliarmus, Expecto Patronum...)
- LOCATION â€“ lokacije (Hogwarts, Forbidden Forest...)

Relacije:
CHARACTER â€“ CHARACTER:
- friend-of, enemy-of, mentor-of, student-of, parent-of, sibling-of, rival-of, ally-of

CHARACTER â€“ HOUSE:
- member-of-house, founder-of-house

CHARACTER â€“ MAGIC_ITEM:
- uses, owns, acquires, gives

CHARACTER â€“ SPELL:
- casts, knows, teaches

CHARACTERâ€“LOCATION:
  - located_in

## ğŸ“š Prikupljanje i priprema podataka

- Dataset: Kaggle Harry Potter knjige (TXT)
- Uklonjeni su naslovi poglavlja i spojeni najkraÄ‡i paragrafe da bi se dobio bolji kontekst
- Tekst nije dodatno ÄiÅ¡Ä‡en jer su LLM modeli veÄ‡ obuÄeni na ovom korpusu  
â†’ scripts/utils.py

MoguÄ‡e poboljÅ¡anje:  
Dodavanje enciklopedijskih reÄenica sa Harry Potter Wiki stranica (koje Äesto eksplicitno sadrÅ¾e relacije) radi proÅ¡irenja domene i pokrivenosti.


## ğŸ” Odabir pasusa

Koristi se cluster-based sampling:
- Svakom pasusu se dodeljuje vektorska reprezentacija (npr. SentenceTransformer)
- Primena KMeans klasterizacije
- NasumiÄni odabir iz svakog klastera obezbeÄ‘uje raznovrsnost  
â†’ scripts/odabir_paragrafa


## âœï¸ Anotacija podataka

- Anotacija pomoÄ‡u LLM-a (GPT-4.1-mini) putem OpenAI API-ja  
  (troÅ¡ak ~600 RSD za celu bazu)

- Prompt ukljuÄuje numerisanje tokena, Å¡to reÅ¡ava veÄ‡inu problema sa token_start i token_end

- Dobijeni anotirani JSON se Äuva kao jedan data point  
â†’ scripts/llm_anotation.py, scripts/helper_classes.py

### ğŸŸ¡ Token checker-i  
Implementirani su jednostavni token checkeri koji proveravaju:
- Da li su token_start i token_end u ispravnom opsegu
- Da li je text entiteta taÄno iseÄen iz tokens
- Da li head i tail u relacijama odgovaraju postojeÄ‡im entitetima  


## âœ… RuÄna validacija â€“ Golden Set

- RuÄno pregledano 225 anotiranih primera formira golden set
- RuÄna validacija je obavljena kroz jednostavnu checker aplikaciju sa GUI-em, koja omoguÄ‡ava:
  - pregled tokenizovanih pasusa
  - izmenu entiteta i relacija
  - brzo oznaÄavanje greÅ¡aka  
â†’ anotation_checker/checker.py  
â†’ anotations/golden_set_checked se koristi za validaciju modela i merenje F1 score-a


## ğŸ¤– Model i fine-tuning

- Model: ner (fine-tuned bert-base) + re (fine-tuned bert-base) 
- Zadaci: Named Entity Recognition (NER) i Relation Extraction (RE)
- OkruÅ¾enje: Google Colab GPU (T4).
- Dataset format je kompatibilan sa veÄ‡inom popularnih RE frameworka
- Fine-tuning pristup:
    - Model je treniran na ~2000 anotiranih primera (veÄ‡ina uz pomoÄ‡ LLM-a, deo ruÄno verifikovan).
    - Goldenset (225 primera) koristi se za validaciju i testiranje.
    - Tokom treniranja koriste se klasiÄne metrike: precision, recall, F1-score, posebno za relacije.
    - Trening je jednostavan nakon Å¡to je dataset pravilno formatiran.

| Model   | F1 Test | F1 Val |
|---------|---------|--------|
| RE      |  0.93   |  0.93  |
| NER     |  0.87   |  0.85  |


## ğŸ“Š Vizualizacija

- KoriÅ¡Ä‡enje networkx + matplotlib za prikaz relacija u formi grafa
- Svaki pasus moÅ¾e biti prikazan kao entitetska mreÅ¾a sa obojenim Ävorovima i strelicama


## ğŸ’¸ TroÅ¡kovi

| Stavka                 | Cena (RSD) |
|------------------------|------------|
| LLM anotacija          | ~600       |
| Golden set ruÄno       | ~2000      |
| Ukupno                 | 2600       |


## ğŸ›  NaÄin koriÅ¡Ä‡enja projekta

Ovaj repozitorijum nije namenjen direktnom pokretanju, veÄ‡ sluÅ¾i kao ilustracija celog pipeline-a: od pripreme podataka, preko anotacije i obuke modela, do evaluacije i vizualizacije.

ZavrÅ¡ni model moÅ¾ete isprobati u interface.py fajlu, koji omoguÄ‡ava jednostavno testiranje i vizualizaciju rezultata.

## ğŸ”„ Pipeline
Projekat je organizovan kao jasno definisan pipeline, od sirovog teksta do krajnjeg testiranja modela. Svaka faza je dokumentovana kroz skripte i Jupyter beleÅ¾nice.

Preprocesiranje teksta
â†’ scripts/utils.py
Originalni tekst knjiga, spaja kraÄ‡e pasuse, Äisti neÅ¾eljeni sadrÅ¾aj (naslovi poglavlja).

Odabir pasusa za anotaciju
â†’ notebooks/odabir_paragrafa.ipynb
Koristi SentenceTransformer + KMeans za raznovrstan uzorak pasusa.

Automatska anotacija pomoÄ‡u LLM-a
â†’ notebooks/anotiranje.ipynb
Slanje pasusa ka GPT API-ju i dobijanje JSON anotacija.
(pomocni fajlovi, prompt.txt, scripts/llm_anotation.py, scripts/helper_classes.py)

RuÄna ispravka anotacija (Golden Set)
â†’ notebooks/ispravka_data.ipynb
Token_start i token_end se prilagodjavaju.

Odabir konaÄnih anotacija za trening/test
â†’ notebooks/odabir_anotacija.ipynb
Selektovanje primera za trening, validaciju i testiranje.

Checker GUI za dodatnu validaciju
â†’ anotation_checker/checker.py
Vizualni alat za proveru ispravnosti entiteta i relacija.

Priprema podataka za treniranje
â†’ notebooks/priprema_podataka_ner.ipynb
â†’ notebooks/priprema_podataka_re.ipynb
Formatiranje anotacija u odgovarajuÄ‡i oblik za NER i RE modele.

Treniranje modela
â†’ train
Fine-tuning BERT modela na pripremljenim podacima.

Testiranje i vizualizacija rezultata
â†’ notebooks/INTERFACE.ipynb
OmoguÄ‡ava unos teksta, prikaz predikcija i crtanje entitetskog grafa.


## Poboljsanja:

Potreban data-aug za obicne recenice tipa: Harry is killing his sworn enemy. itd...
Kada treniras re i ner zameni imena sa nekim dugim imenima kako bi model kasnije bolje generalizovao.# Relation-Extraction-Harry-Potter
# Relation-Extraction-Harry-Potter
